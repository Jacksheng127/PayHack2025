{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63297185",
   "metadata": {},
   "source": [
    "# GNN Anomaly Detection with GAE + GraphSAGE using BankSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a2c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
      "0     0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
      "1     0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
      "2     0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
      "3     0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
      "4     0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
      "\n",
      "              category  amount  fraud  \n",
      "0  'es_transportation'    4.55      0  \n",
      "1  'es_transportation'   39.68      0  \n",
      "2  'es_transportation'   26.89      0  \n",
      "3  'es_transportation'   17.25      0  \n",
      "4  'es_transportation'   35.72      0  \n",
      "fraud\n",
      "0    587443\n",
      "1      7200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/bs140513_032310.csv')\n",
    "print(df.head())\n",
    "print(df['fraud'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be21543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def get_numeric_id(customer_id):\n",
    "    numeric_only = re.sub(r'[^0-9]', '', str(customer_id))\n",
    "    return int(numeric_only) if numeric_only else 0\n",
    "\n",
    "df['device_fp'] = df['customer'].apply(lambda x: f\"fp_{get_numeric_id(x) % 1000}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254201ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in df.iterrows():\n",
    "    if row['fraud'] == 0:  # Use only normal transactions for training\n",
    "        u = f\"user_{row['customer']}\"\n",
    "        m = f\"merch_{row['merchant']}\"\n",
    "        G.add_node(u, type='user')\n",
    "        G.add_node(m, type='merchant')\n",
    "        G.add_edge(u, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a17f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data = from_networkx(G)\n",
    "data.x = torch.eye(data.num_nodes)  # Identity features as placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ef7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import GAE, SAGEConv\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = SAGEConv(2 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "encoder = GNNEncoder(data.num_node_features, 32)\n",
    "model = GAE(encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a55e321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Henry\\Doucments\\Documents\\UM\\sem5\\payhack\\PayHack2025-1\\payhackenv\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.0605\n",
      "Epoch 20, Loss: 0.8523\n",
      "Epoch 30, Loss: 1.1409\n",
      "Epoch 40, Loss: 0.9314\n",
      "Epoch 50, Loss: 0.8461\n",
      "Epoch 60, Loss: 0.8142\n",
      "Epoch 70, Loss: 0.7971\n",
      "Epoch 80, Loss: 0.7859\n",
      "Epoch 90, Loss: 0.7766\n",
      "Epoch 100, Loss: 0.7718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d39c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9960\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.train_pos_edge_index)\n",
    "    pos_pred = model.decoder(z, data.test_pos_edge_index).squeeze()\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index,\n",
    "        num_nodes=z.size(0),\n",
    "        num_neg_samples=data.test_pos_edge_index.size(1)\n",
    "    )\n",
    "    neg_pred = model.decoder(z, neg_edge_index).squeeze()\n",
    "\n",
    "    y_true = torch.cat([torch.ones(pos_pred.size(0)), torch.zeros(neg_pred.size(0))])\n",
    "    y_score = torch.cat([pos_pred, neg_pred])\n",
    "\n",
    "    auc = roc_auc_score(y_true.cpu(), y_score.cpu())\n",
    "    print(f\"AUC Score: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbe0d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and create node mapping for production use\n",
    "import pickle\n",
    "\n",
    "# Create node mapping for faster lookup\n",
    "node_mapping = {}\n",
    "for i, node in enumerate(G.nodes()):\n",
    "    node_mapping[node] = i\n",
    "\n",
    "# Save model and necessary data\n",
    "model_data = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'node_mapping': node_mapping,\n",
    "    'data': data,\n",
    "    'encoder_config': {'in_channels': data.num_node_features, 'out_channels': 32}\n",
    "}\n",
    "\n",
    "torch.save(model_data, '../outputs/fraud_detection_model.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec10e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud detection wrapper initialized!\n"
     ]
    }
   ],
   "source": [
    "class FraudDetectionWrapper:\n",
    "    \"\"\"\n",
    "    Production wrapper for the GNN fraud detection model\n",
    "    Handles preprocessing, prediction, and output formatting for web API integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str = None):\n",
    "        self.model = None\n",
    "        self.node_mapping = {}\n",
    "        self.data = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        if model_path:\n",
    "            self.load_model(model_path)\n",
    "    \n",
    "    def get_numeric_id(self, customer_id):\n",
    "        \"\"\"Extract numeric ID from customer string\"\"\"\n",
    "        numeric_only = re.sub(r'[^0-9]', '', str(customer_id))\n",
    "        return int(numeric_only) if numeric_only else 0\n",
    "    \n",
    "    def preprocess_transaction(self, transaction_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Preprocess a single transaction for model input\n",
    "        \n",
    "        Required inputs in transaction_data:\n",
    "        - customer: Customer ID (string) - e.g., \"C1093826151\"\n",
    "        - merchant: Merchant ID (string) - e.g., \"M348934600\"\n",
    "        - amount: Transaction amount (float) - e.g., 156.50\n",
    "        - category: Transaction category (string) - e.g., \"es_transportation\"\n",
    "        - age: Customer age (int) - e.g., 4\n",
    "        - gender: Customer gender (string) - e.g., \"M\" or \"F\"\n",
    "        - zipcodeOri: Customer zipcode (string) - e.g., \"28007\"\n",
    "        - zipMerchant: Merchant zipcode (string) - e.g., \"28007\"\n",
    "        \"\"\"\n",
    "        processed = {\n",
    "            'customer_node': f\"user_{transaction_data['customer']}\",\n",
    "            'merchant_node': f\"merch_{transaction_data['merchant']}\",\n",
    "            'amount': float(transaction_data['amount']),\n",
    "            'customer_age': int(transaction_data['age']),\n",
    "            'same_zipcode': transaction_data['zipcodeOri'] == transaction_data['zipMerchant'],\n",
    "            'category': transaction_data['category'],\n",
    "            'gender': transaction_data['gender'],\n",
    "            'device_fp': f\"fp_{self.get_numeric_id(transaction_data['customer']) % 1000}\"\n",
    "        }\n",
    "        return processed\n",
    "    \n",
    "    def calculate_anomaly_score(self, transaction_data: dict) -> float:\n",
    "        \"\"\"\n",
    "        Calculate anomaly score for a transaction\n",
    "        Returns: Float between 0-1 (higher = more suspicious)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded. Call load_model() first.\")\n",
    "            \n",
    "        self.model.eval()\n",
    "        processed = self.preprocess_transaction(transaction_data)\n",
    "        \n",
    "        customer_node = processed['customer_node']\n",
    "        merchant_node = processed['merchant_node']\n",
    "        \n",
    "        # Check if nodes exist in trained graph\n",
    "        if customer_node not in self.node_mapping or merchant_node not in self.node_mapping:\n",
    "            return self._calculate_new_entity_score(processed)\n",
    "        \n",
    "        # Get node embeddings and calculate link probability\n",
    "        with torch.no_grad():\n",
    "            z = self.model.encode(self.data.x, self.data.train_pos_edge_index)\n",
    "            \n",
    "            customer_idx = self.node_mapping[customer_node]\n",
    "            merchant_idx = self.node_mapping[merchant_node]\n",
    "            \n",
    "            # Calculate reconstruction probability\n",
    "            edge_index = torch.tensor([[customer_idx], [merchant_idx]], dtype=torch.long)\n",
    "            link_prob = torch.sigmoid(self.model.decoder(z, edge_index)).item()\n",
    "            \n",
    "            # Convert to anomaly score (lower link probability = higher anomaly)\n",
    "            base_anomaly = 1 - link_prob\n",
    "            \n",
    "            # Apply business rules\n",
    "            anomaly_score = self._apply_business_rules(base_anomaly, processed)\n",
    "            \n",
    "        return min(max(anomaly_score, 0.0), 1.0)  # Clamp between 0-1\n",
    "    \n",
    "    def _calculate_new_entity_score(self, processed: dict) -> float:\n",
    "        \"\"\"Handle transactions with new customers/merchants\"\"\"\n",
    "        base_score = 0.3  # Base suspicion for new entities\n",
    "        \n",
    "        # Adjust based on amount\n",
    "        if processed['amount'] > 1000:\n",
    "            base_score += 0.2\n",
    "        elif processed['amount'] > 500:\n",
    "            base_score += 0.1\n",
    "            \n",
    "        # Adjust based on location\n",
    "        if not processed['same_zipcode']:\n",
    "            base_score += 0.1\n",
    "            \n",
    "        return min(base_score, 1.0)\n",
    "    \n",
    "    def _apply_business_rules(self, base_score: float, processed: dict) -> float:\n",
    "        \"\"\"Apply business rules to adjust anomaly score\"\"\"\n",
    "        adjusted_score = base_score\n",
    "        \n",
    "        # High amount transactions\n",
    "        if processed['amount'] > 1000:\n",
    "            adjusted_score += 0.2\n",
    "        elif processed['amount'] > 500:\n",
    "            adjusted_score += 0.1\n",
    "            \n",
    "        # Cross-location transactions\n",
    "        if not processed['same_zipcode']:\n",
    "            adjusted_score += 0.15\n",
    "            \n",
    "        # Suspicious categories (customize based on your domain)\n",
    "        suspicious_categories = ['es_health', 'es_hyper', 'es_wellnessandbeauty']\n",
    "        if processed['category'] in suspicious_categories and processed['amount'] > 200:\n",
    "            adjusted_score += 0.1\n",
    "            \n",
    "        return adjusted_score\n",
    "    \n",
    "    def predict_fraud(self, transaction_data: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Main prediction method for web API\n",
    "        \n",
    "        Input: Dictionary with transaction details\n",
    "        Output: Dictionary with fraud prediction results\n",
    "        \"\"\"\n",
    "        anomaly_score = self.calculate_anomaly_score(transaction_data)\n",
    "        \n",
    "        # Define risk thresholds\n",
    "        high_risk_threshold = 0.7\n",
    "        medium_risk_threshold = 0.4\n",
    "        \n",
    "        # Determine fraud prediction\n",
    "        is_fraud = anomaly_score > high_risk_threshold\n",
    "        fraud_probability = anomaly_score\n",
    "        \n",
    "        # Risk level classification\n",
    "        if anomaly_score > high_risk_threshold:\n",
    "            risk_level = \"HIGH\"\n",
    "        elif anomaly_score > medium_risk_threshold:\n",
    "            risk_level = \"MEDIUM\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "        \n",
    "        # Identify risk factors for explainability\n",
    "        risk_factors = self._identify_risk_factors(transaction_data, anomaly_score)\n",
    "        \n",
    "        return {\n",
    "            'is_fraud': is_fraud,\n",
    "            'fraud_probability': round(fraud_probability, 3),\n",
    "            'risk_level': risk_level,\n",
    "            'anomaly_score': round(anomaly_score, 3),\n",
    "            'risk_factors': risk_factors,\n",
    "            'transaction_id': transaction_data.get('transaction_id', 'N/A')\n",
    "        }\n",
    "    \n",
    "    def _identify_risk_factors(self, transaction_data: dict, anomaly_score: float) -> list:\n",
    "        \"\"\"Identify specific risk factors for explainability\"\"\"\n",
    "        factors = []\n",
    "        \n",
    "        if float(transaction_data['amount']) > 1000:\n",
    "            factors.append(\"High transaction amount (>$1000)\")\n",
    "        elif float(transaction_data['amount']) > 500:\n",
    "            factors.append(\"Elevated transaction amount (>$500)\")\n",
    "        \n",
    "        if transaction_data['zipcodeOri'] != transaction_data['zipMerchant']:\n",
    "            factors.append(\"Cross-location transaction\")\n",
    "        \n",
    "        if anomaly_score > 0.5:\n",
    "            factors.append(\"Unusual customer-merchant relationship pattern\")\n",
    "        \n",
    "        # Check for new entities\n",
    "        customer_node = f\"user_{transaction_data['customer']}\"\n",
    "        merchant_node = f\"merch_{transaction_data['merchant']}\"\n",
    "        \n",
    "        if customer_node not in self.node_mapping:\n",
    "            factors.append(\"New customer (not seen in training data)\")\n",
    "        if merchant_node not in self.node_mapping:\n",
    "            factors.append(\"New merchant (not seen in training data)\")\n",
    "        \n",
    "        return factors\n",
    "    \n",
    "    def load_model(self, model_path: str):\n",
    "        \"\"\"Load a pre-trained model from file\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "            \n",
    "            # Reconstruct model architecture\n",
    "            encoder_config = checkpoint.get('encoder_config', {'in_channels': 1000, 'out_channels': 32})\n",
    "            encoder = GNNEncoder(encoder_config['in_channels'], encoder_config['out_channels'])\n",
    "            self.model = GAE(encoder)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            self.node_mapping = checkpoint['node_mapping']\n",
    "            self.data = checkpoint['data']\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            \n",
    "            print(f\"Model loaded successfully from {model_path}\")\n",
    "            print(f\"Graph has {len(self.node_mapping)} nodes\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to load model: {str(e)}\")\n",
    "\n",
    "# Create an instance of the wrapper\n",
    "fraud_detector = FraudDetectionWrapper()\n",
    "fraud_detector.model = model\n",
    "fraud_detector.node_mapping = node_mapping\n",
    "fraud_detector.data = data\n",
    "\n",
    "print(\"Fraud detection wrapper initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e06bacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Fraud Detection Wrapper ===\n",
      "Transaction: $156.5 from C1093826151 to M348934600\n",
      "Fraud Prediction: False\n",
      "Risk Level: LOW\n",
      "Fraud Probability: 0.3\n",
      "Anomaly Score: 0.3\n",
      "Risk Factors: ['New customer (not seen in training data)', 'New merchant (not seen in training data)']\n",
      "\n",
      "High Amount Transaction: $1500.0\n",
      "Fraud Prediction: False\n",
      "Risk Level: MEDIUM\n",
      "Risk Factors: ['High transaction amount (>$1000)', 'Cross-location transaction', 'Unusual customer-merchant relationship pattern', 'New customer (not seen in training data)', 'New merchant (not seen in training data)']\n"
     ]
    }
   ],
   "source": [
    "# Test the fraud detection wrapper with sample data\n",
    "print(\"=== Testing Fraud Detection Wrapper ===\")\n",
    "\n",
    "# Example transaction data (based on your dataset structure)\n",
    "sample_transaction = {\n",
    "    'customer': 'C1093826151',\n",
    "    'merchant': 'M348934600', \n",
    "    'amount': 156.50,\n",
    "    'category': 'es_transportation',\n",
    "    'age': 4,\n",
    "    'gender': 'M',\n",
    "    'zipcodeOri': '28007',\n",
    "    'zipMerchant': '28007',\n",
    "    'transaction_id': 'TXN_001'\n",
    "}\n",
    "\n",
    "# Get fraud prediction\n",
    "result = fraud_detector.predict_fraud(sample_transaction)\n",
    "\n",
    "print(f\"Transaction: ${sample_transaction['amount']} from {sample_transaction['customer']} to {sample_transaction['merchant']}\")\n",
    "print(f\"Fraud Prediction: {result['is_fraud']}\")\n",
    "print(f\"Risk Level: {result['risk_level']}\")\n",
    "print(f\"Fraud Probability: {result['fraud_probability']}\")\n",
    "print(f\"Anomaly Score: {result['anomaly_score']}\")\n",
    "print(f\"Risk Factors: {result['risk_factors']}\")\n",
    "print()\n",
    "\n",
    "# Test with a high-amount transaction\n",
    "high_amount_transaction = sample_transaction.copy()\n",
    "high_amount_transaction['amount'] = 1500.0\n",
    "high_amount_transaction['zipMerchant'] = '90210'  # Different zipcode\n",
    "\n",
    "result_high = fraud_detector.predict_fraud(high_amount_transaction)\n",
    "print(f\"High Amount Transaction: ${high_amount_transaction['amount']}\")\n",
    "print(f\"Fraud Prediction: {result_high['is_fraud']}\")\n",
    "print(f\"Risk Level: {result_high['risk_level']}\")\n",
    "print(f\"Risk Factors: {result_high['risk_factors']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16640a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask API example for web integration\n",
    "flask_api_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "from fraud_detection_wrapper import FraudDetectionWrapper\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for web frontend integration\n",
    "\n",
    "# Load the trained model (update path as needed)\n",
    "fraud_detector = FraudDetectionWrapper('models/fraud_detection_model.pth')\n",
    "\n",
    "@app.route('/api/predict_fraud', methods=['POST'])\n",
    "def predict_fraud():\n",
    "    \"\"\"\n",
    "    API endpoint for fraud prediction\n",
    "    \n",
    "    Expected JSON input:\n",
    "    {\n",
    "        \"customer\": \"C1093826151\",\n",
    "        \"merchant\": \"M348934600\", \n",
    "        \"amount\": 156.50,\n",
    "        \"category\": \"es_transportation\",\n",
    "        \"age\": 4,\n",
    "        \"gender\": \"M\",\n",
    "        \"zipcodeOri\": \"28007\",\n",
    "        \"zipMerchant\": \"28007\",\n",
    "        \"transaction_id\": \"TXN_001\"  // optional\n",
    "    }\n",
    "    \n",
    "    Returns JSON:\n",
    "    {\n",
    "        \"is_fraud\": false,\n",
    "        \"fraud_probability\": 0.234,\n",
    "        \"risk_level\": \"LOW\",\n",
    "        \"anomaly_score\": 0.234,\n",
    "        \"risk_factors\": [\"High transaction amount\"],\n",
    "        \"transaction_id\": \"TXN_001\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate request\n",
    "        if not request.is_json:\n",
    "            return jsonify({'error': 'Request must be JSON'}), 400\n",
    "        \n",
    "        transaction_data = request.json\n",
    "        \n",
    "        # Validate required fields\n",
    "        required_fields = ['customer', 'merchant', 'amount', 'category', 'age', 'gender', 'zipcodeOri', 'zipMerchant']\n",
    "        for field in required_fields:\n",
    "            if field not in transaction_data:\n",
    "                return jsonify({'error': f'Missing required field: {field}'}), 400\n",
    "        \n",
    "        # Get fraud prediction\n",
    "        result = fraud_detector.predict_fraud(transaction_data)\n",
    "        \n",
    "        return jsonify(result), 200\n",
    "        \n",
    "    except ValueError as ve:\n",
    "        return jsonify({'error': f'Validation error: {str(ve)}'}), 400\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Internal server error: {str(e)}'}), 500\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({'status': 'healthy', 'model_loaded': fraud_detector.model is not None}), 200\n",
    "\n",
    "@app.route('/api/model_info', methods=['GET'])\n",
    "def model_info():\n",
    "    \"\"\"Get model information\"\"\"\n",
    "    try:\n",
    "        info = {\n",
    "            'model_type': 'GAE + GraphSAGE',\n",
    "            'num_nodes': len(fraud_detector.node_mapping) if fraud_detector.node_mapping else 0,\n",
    "            'device': str(fraud_detector.device),\n",
    "            'required_fields': ['customer', 'merchant', 'amount', 'category', 'age', 'gender', 'zipcodeOri', 'zipMerchant']\n",
    "        }\n",
    "        return jsonify(info), 200\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Starting Fraud Detection API...\")\n",
    "    print(\"Available endpoints:\")\n",
    "    print(\"  POST /api/predict_fraud - Main prediction endpoint\")\n",
    "    print(\"  GET  /api/health - Health check\")\n",
    "    print(\"  GET  /api/model_info - Model information\")\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n",
    "'''\n",
    "\n",
    "print(\"Flask API code generated!\")\n",
    "print(\"To use this API:\")\n",
    "print(\"1. Save the above code as 'fraud_api.py'\")\n",
    "print(\"2. Install Flask: pip install flask flask-cors\")\n",
    "print(\"3. Run: python fraud_api.py\")\n",
    "print(\"4. API will be available at http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78b0f9",
   "metadata": {},
   "source": [
    "# Model Integration Summary\n",
    "\n",
    "## Required Inputs for Fraud Detection\n",
    "\n",
    "Your GNN model requires the following fields for each transaction:\n",
    "\n",
    "| Field | Type | Description | Example |\n",
    "|-------|------|-------------|---------|\n",
    "| `customer` | string | Customer ID | \"C1093826151\" |\n",
    "| `merchant` | string | Merchant ID | \"M348934600\" |\n",
    "| `amount` | float | Transaction amount | 156.50 |\n",
    "| `category` | string | Transaction category | \"es_transportation\" |\n",
    "| `age` | int | Customer age | 4 |\n",
    "| `gender` | string | Customer gender | \"M\" or \"F\" |\n",
    "| `zipcodeOri` | string | Customer zipcode | \"28007\" |\n",
    "| `zipMerchant` | string | Merchant zipcode | \"28007\" |\n",
    "| `transaction_id` | string | Optional transaction ID | \"TXN_001\" |\n",
    "\n",
    "## Model Outputs\n",
    "\n",
    "The model returns a JSON object with:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| `is_fraud` | boolean | Binary fraud prediction (true/false) |\n",
    "| `fraud_probability` | float | Fraud probability score (0.0 - 1.0) |\n",
    "| `risk_level` | string | Risk classification (\"LOW\", \"MEDIUM\", \"HIGH\") |\n",
    "| `anomaly_score` | float | Raw anomaly score (0.0 - 1.0) |\n",
    "| `risk_factors` | array | List of identified risk factors |\n",
    "| `transaction_id` | string | Transaction ID (if provided) |\n",
    "\n",
    "## Integration Steps\n",
    "\n",
    "1. **Save the model**: Run the model saving cell to create `fraud_detection_model.pth`\n",
    "2. **Deploy the wrapper**: Use the `FraudDetectionWrapper` class in your application\n",
    "3. **Create API endpoint**: Use the Flask example to create a REST API\n",
    "4. **Connect to frontend**: Your web app can POST transaction data to `/api/predict_fraud`\n",
    "\n",
    "## Risk Thresholds\n",
    "\n",
    "- **HIGH RISK** (≥0.7): Block transaction, require manual review\n",
    "- **MEDIUM RISK** (0.4-0.7): Flag for additional verification\n",
    "- **LOW RISK** (<0.4): Allow transaction to proceed\n",
    "\n",
    "## Business Rules Applied\n",
    "\n",
    "- High amount transactions (>$500, >$1000)\n",
    "- Cross-location transactions (different zipcodes)\n",
    "- New customers/merchants not in training data\n",
    "- Suspicious categories (configurable)\n",
    "- Unusual customer-merchant relationship patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "payhackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
