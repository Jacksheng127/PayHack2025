{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c7f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4880257",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FILE = \"../data/elliptic_txs_features.csv\"\n",
    "CLASS_FILE = \"../data/elliptic_txs_classes.csv\"\n",
    "EDGE_FILE = \"../data/elliptic_txs_edgelist.csv\"\n",
    "\n",
    "# OUTPUT_CSV = \"../output/elliptic_mini.csv\"\n",
    "# OUTPUT_GRAPH = \"../output/elliptic_graph.gpickle\"\n",
    "\n",
    "# how many features to keep\n",
    "N_FEATURES = 15\n",
    "# maximum time_step (optional filter to shrink dataset)\n",
    "MAX_TIMESTEP = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5a040",
   "metadata": {},
   "source": [
    "## combine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f5b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loading features...\n",
      "📄 Loading labels...\n",
      "📄 Merging features & labels...\n",
      "📄 Loading labels...\n",
      "📄 Merging features & labels...\n"
     ]
    }
   ],
   "source": [
    "print(\"📄 Loading features...\")\n",
    "df_features = pd.read_csv(FEATURE_FILE, header=None)\n",
    "\n",
    "# assign column names\n",
    "n_cols = df_features.shape[1]\n",
    "columns = ['txId', 'time_step'] + [f'V{i}' for i in range(1, n_cols - 1)]\n",
    "df_features.columns = columns\n",
    "\n",
    "df_features['txId'] = df_features['txId'].astype(str)\n",
    "\n",
    "print(\"📄 Loading labels...\")\n",
    "df_labels = pd.read_csv(CLASS_FILE, header=None, names=['txId', 'class'])\n",
    "df_labels['txId'] = df_labels['txId'].astype(str)\n",
    "\n",
    "print(\"📄 Merging features & labels...\")\n",
    "df = df_features.merge(df_labels, on='txId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a407a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203769, 168)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f332f9",
   "metadata": {},
   "source": [
    "## Small elliptic - without unknown pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3cb3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 After filtering, shape: (46564, 168)\n",
      "class\n",
      "2    42019\n",
      "1     4545\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['class'].isin(['1', '2'])]\n",
    "print(f\"📊 After filtering, shape: {df.shape}\")\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b390e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned dataset to: output\\elliptic_mini.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# make sure output folder exists\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# save cleaned dataset\n",
    "OUTPUT_CSV = os.path.join(\"output\", \"elliptic_mini.csv\")\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"✅ Saved cleaned dataset to: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171113a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e9b7a",
   "metadata": {},
   "source": [
    "## Generate graph and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b6c7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loading cleaned dataset...\n",
      "✅ Loaded dataset: (46564, 168)\n",
      "📄 Loading edge list...\n",
      "✅ Cleaned edges: (234355, 2)\n",
      "🕸️ Building graph...\n",
      "✅ Loaded dataset: (46564, 168)\n",
      "📄 Loading edge list...\n",
      "✅ Cleaned edges: (234355, 2)\n",
      "🕸️ Building graph...\n",
      "✅ Graph: 203769 nodes, 234355 edges\n",
      "📝 Attaching node features & labels...\n",
      "✅ Graph: 203769 nodes, 234355 edges\n",
      "📝 Attaching node features & labels...\n",
      "✅ Final graph: 0 nodes, 0 edges\n",
      "📄 Sample node: []\n",
      "✅ Saved cleaned graph to: output\\elliptic_graph.gpickle\n",
      "✅ Final graph: 0 nodes, 0 edges\n",
      "📄 Sample node: []\n",
      "✅ Saved cleaned graph to: output\\elliptic_graph.gpickle\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "EDGE_FILE = \"../data/elliptic_txs_edgelist.csv\"\n",
    "OUTPUT_GRAPH = os.path.join(\"output\", \"elliptic_graph.gpickle\")\n",
    "\n",
    "# Load the cleaned dataset that was saved earlier\n",
    "print(\"📄 Loading cleaned dataset...\")\n",
    "df = pd.read_csv(\"output/elliptic_mini.csv\")\n",
    "print(f\"✅ Loaded dataset: {df.shape}\")\n",
    "\n",
    "print(\"📄 Loading edge list...\")\n",
    "df_edges = pd.read_csv(EDGE_FILE, header=None, names=['source', 'target'])\n",
    "\n",
    "# ✅ Remove invalid header row if present\n",
    "df_edges = df_edges[df_edges['source'] != 'txId1']\n",
    "df_edges = df_edges[df_edges['target'] != 'txId2']\n",
    "\n",
    "print(f\"✅ Cleaned edges: {df_edges.shape}\")\n",
    "\n",
    "print(\"🕸️ Building graph...\")\n",
    "G = nx.from_pandas_edgelist(\n",
    "    df_edges,\n",
    "    source='source',\n",
    "    target='target',\n",
    "    create_using=nx.DiGraph()\n",
    ")\n",
    "\n",
    "print(f\"✅ Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# attach node features & labels\n",
    "print(\"📝 Attaching node features & labels...\")\n",
    "feature_dict = df.set_index('txId').to_dict(orient='index')\n",
    "nx.set_node_attributes(G, feature_dict)\n",
    "\n",
    "# optional: remove nodes with no features\n",
    "nodes_with_attrs = set(feature_dict.keys())\n",
    "nodes_to_remove = [n for n in G if n not in nodes_with_attrs]\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "print(f\"✅ Final graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"📄 Sample node: {list(G.nodes(data=True))[:1]}\")\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "with open(\"output/elliptic_graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(G, f)\n",
    "\n",
    "print(f\"✅ Saved cleaned graph to: {OUTPUT_GRAPH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a382402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph loaded: 0 nodes, 0 edges\n"
     ]
    }
   ],
   "source": [
    "with open(\"output/elliptic_graph.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "print(f\"✅ Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e55bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded: 0 nodes, 0 edges\n",
      "\n",
      "Sample nodes with data:\n",
      "\n",
      "Sample edges with data:\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "# Load the graph using pickle\n",
    "with open(\"output/elliptic_graph.gpickle\", 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(\"\\nSample nodes with data:\")\n",
    "for i, (node, data) in enumerate(G.nodes(data=True)):\n",
    "    if i < 3:  # Show first 3 nodes\n",
    "        print(f\"Node {node}: {data}\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"\\nSample edges with data:\")\n",
    "for i, (u, v, data) in enumerate(G.edges(data=True)):\n",
    "    if i < 3:  # Show first 3 edges\n",
    "        print(f\"Edge {u} -> {v}: {data}\")\n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "payhackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
